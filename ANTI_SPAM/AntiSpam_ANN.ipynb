{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from scipy import optimize\n",
    "class Anti_SPAM_ANN_Approach(object):\n",
    "    def __init__(self, Lambda=0):        \n",
    "        #Define Hyperparameters\n",
    "        self.inputLayerSize = 2\n",
    "        self.outputLayerSize = 1\n",
    "        self.hiddenLayerSize = 3\n",
    "        \n",
    "        #Weights (parameters)\n",
    "        self.W1 = np.random.randn(self.inputLayerSize,self.hiddenLayerSize)\n",
    "        self.W2 = np.random.randn(self.hiddenLayerSize,self.outputLayerSize)\n",
    "        \n",
    "        #Regularization Parameter:\n",
    "        self.Lambda = Lambda\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.z2 = np.dot(X, self.W1)\n",
    "        self.a2 = self.sigmoid(self.z2)\n",
    "        self.z3 = np.dot(self.a2, self.W2)\n",
    "        yHat = self.sigmoid(self.z3) \n",
    "        return yHat\n",
    "        \n",
    "    def sigmoid(self, z):\n",
    "        #Apply sigmoid activation function to scalar, vector, or matrix\n",
    "        return 1/(1+np.exp(-z))\n",
    "    \n",
    "    def sigmoidPrime(self,z):\n",
    "        #Gradient of sigmoid\n",
    "        return np.exp(-z)/((1+np.exp(-z))**2)\n",
    "    \n",
    "    def costFunction(self, X, y):\n",
    "        #Compute cost for given X,y, use weights already stored in class.\n",
    "        self.yHat = self.forward(X)\n",
    "        J = 0.5*sum((y-self.yHat)**2)/X.shape[0] + (self.Lambda/2)*(np.sum(self.W1**2)+np.sum(self.W2**2))\n",
    "        return J\n",
    "        \n",
    "    def costFunctionPrime(self, X, y):\n",
    "        #Compute derivative with respect to W and W2 for a given X and y:\n",
    "        self.yHat = self.forward(X)\n",
    "        \n",
    "        delta3 = np.multiply(-(y-self.yHat), self.sigmoidPrime(self.z3))\n",
    "        #Add gradient of regularization term:\n",
    "        dJdW2 = np.dot(self.a2.T, delta3)/X.shape[0] + self.Lambda*self.W2\n",
    "        \n",
    "        delta2 = np.dot(delta3, self.W2.T)*self.sigmoidPrime(self.z2)\n",
    "        #Add gradient of regularization term:\n",
    "        dJdW1 = np.dot(X.T, delta2)/X.shape[0] + self.Lambda*self.W1\n",
    "        \n",
    "        return dJdW1, dJdW2\n",
    "    \n",
    "    #Helper functions for interacting with other methods/classes\n",
    "    def getParams(self):\n",
    "        #Get W1 and W2 Rolled into vector:\n",
    "        params = np.concatenate((self.W1.ravel(), self.W2.ravel()))\n",
    "        return params\n",
    "    \n",
    "    def setParams(self, params):\n",
    "        #Set W1 and W2 using single parameter vector:\n",
    "        W1_start = 0\n",
    "        W1_end = self.hiddenLayerSize*self.inputLayerSize\n",
    "        self.W1 = np.reshape(params[W1_start:W1_end], \\\n",
    "                             (self.inputLayerSize, self.hiddenLayerSize))\n",
    "        W2_end = W1_end + self.hiddenLayerSize*self.outputLayerSize\n",
    "        self.W2 = np.reshape(params[W1_end:W2_end], \\\n",
    "                             (self.hiddenLayerSize, self.outputLayerSize))\n",
    "        \n",
    "    def computeGradients(self, X, y):\n",
    "        dJdW1, dJdW2 = self.costFunctionPrime(X, y)\n",
    "        return np.concatenate((dJdW1.ravel(), dJdW2.ravel()))\n",
    "\n",
    "\n",
    "\n",
    "class trainer(object):\n",
    "    def __init__(self, N):\n",
    "        #Make Local reference to network:\n",
    "        self.N = N\n",
    "        \n",
    "    def callbackF(self, params):\n",
    "        self.N.setParams(params)\n",
    "        self.J.append(self.N.costFunction(self.X, self.y))   \n",
    "        \n",
    "    def costFunctionWrapper(self, params, X, y):\n",
    "        self.N.setParams(params)\n",
    "        cost = self.N.costFunction(X, y)\n",
    "        grad = self.N.computeGradients(X,y)\n",
    "        \n",
    "        return cost, grad\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        #Make an internal variable for the callback function:\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "        #Make empty list to store costs:\n",
    "        self.J = []\n",
    "        \n",
    "        params0 = self.N.getParams()\n",
    "\n",
    "        options = {'maxiter': 200, 'disp' : True}\n",
    "        _res = optimize.minimize(self.costFunctionWrapper, params0, jac=True, method='BFGS', \\\n",
    "                                 args=(X, y), options=options, callback=self.callbackF)\n",
    "\n",
    "        self.N.setParams(_res.x)\n",
    "        self.optimizationResults = _res\n",
    "#Train_DATA \n",
    "X=np.array(([0.16129032258064513, 0.31875], [0.19354838709677424, 0.3322222222222222], [0.12903225806451613, 0.4130081300813008], [0.16129032258064513, 0.31749999999999995], [0.19354838709677424, 0.17843137254901958], [0.19354838709677424, 0.15069444444444444], [0.16129032258064513, 0.28385826771653544], [0.12903225806451613, 0.175], [0.12903225806451613, 0.19209302325581395], [0.12903225806451613, 0.12727272727272726]),dtype=float)\n",
    "Y=np.array(([0],[0],[0],[0],[1],[1],[1],[1],[1],[1]),dtype=float)\n",
    "\n",
    "#Test_DATA \n",
    "XT=np.array(([0.16129032258064513, 0.175],\n",
    " [0.12903225806451613, 0.182],\n",
    " [0.12903225806451613, 0.23890243902439023]),dtype=float)\n",
    "YT=np.array(([1],[1],[1]),dtype=float)\n",
    "\n",
    "#Scaling of Data \n",
    "X=X/np.amax(X,axis=0)\n",
    "Y=Y/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.49715626],\n",
       "       [ 0.49645157],\n",
       "       [ 0.49635454],\n",
       "       [ 0.49717301],\n",
       "       [ 0.49866999],\n",
       "       [ 0.49914825],\n",
       "       [ 0.49763902],\n",
       "       [ 0.49991476],\n",
       "       [ 0.49961696],\n",
       "       [ 0.50078049]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN=Anti_SPAM_ANN_Approach()\n",
    "NN.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.49715626],\n",
       "       [ 0.49645157],\n",
       "       [ 0.49635454],\n",
       "       [ 0.49717301],\n",
       "       [ 0.49866999],\n",
       "       [ 0.49914825],\n",
       "       [ 0.49763902],\n",
       "       [ 0.49991476],\n",
       "       [ 0.49961696],\n",
       "       [ 0.50078049]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T=trainer(NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 63\n",
      "         Function evaluations: 77\n",
      "         Gradient evaluations: 77\n"
     ]
    }
   ],
   "source": [
    "T.train(X,Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.76617641e-17],\n",
       "       [  9.44790120e-04],\n",
       "       [  1.01495250e-22],\n",
       "       [  5.61276423e-17],\n",
       "       [  1.00000000e+00],\n",
       "       [  1.00000000e+00],\n",
       "       [  9.98305320e-01],\n",
       "       [  1.00000000e+00],\n",
       "       [  1.00000000e+00],\n",
       "       [  1.00000000e+00]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 0\n",
      "         Function evaluations: 1\n",
      "         Gradient evaluations: 1\n"
     ]
    }
   ],
   "source": [
    "T.train(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.45463032e-06],\n",
       "       [  1.64153316e-04],\n",
       "       [  1.50080941e-17],\n",
       "       [  7.69670999e-06],\n",
       "       [  1.00000000e+00],\n",
       "       [  1.00000000e+00],\n",
       "       [  9.98434102e-01],\n",
       "       [  1.00000000e+00],\n",
       "       [  1.00000000e+00],\n",
       "       [  1.00000000e+00]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.forward(XT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import dns.resolver\n",
    "import sys\n",
    "import socket\n",
    "list_train=os.listdir(r'C:\\Users\\asus\\Desktop\\Etudes\\S4\\ProjetAI\\train')\n",
    "list_test=os.listdir(r'C:\\Users\\asus\\Desktop\\Etudes\\S4\\ProjetAI\\test')\n",
    "list_train\n",
    "list_test\n",
    "file=r'C:\\Users\\asus\\Desktop\\Etudes\\S4\\ProjetAI\\jargon.txt'\n",
    "\n",
    "def tokenize_text(list_train):\n",
    "\tdir=r'C:\\Users\\asus\\Desktop\\Etudes\\S4\\ProjetAI\\train'\n",
    "\tGtoken=[]\n",
    "\tfor file in list_train:\n",
    "\t\ttoken=[]  \n",
    "\t\tchaine=\"  \"\n",
    "\t\tf = open(dir+'\\\\'+file, 'r')\n",
    "\t\ttoken.append(file)\n",
    "\t\tfor line in f.readlines():\n",
    "\t\t\tif len(token)<=4: \n",
    "\t\t\t\ttoken.append(line) \n",
    "\t\t\telse:\n",
    "\t\t\t\tchaine=chaine+line \n",
    "\t\ttoken.append(chaine)                 \n",
    "\t\tf.close()\n",
    "\t\tGtoken.append(token)\n",
    "\treturn Gtoken\n",
    "p=tokenize_text(list_train)\n",
    "def tokenize_text(list_test):\n",
    "\tdir=r'C:\\Users\\asus\\Desktop\\Etudes\\S4\\ProjetAI\\test'\n",
    "\tGtoken=[]\n",
    "\tfor file in list_test:\n",
    "\t\ttoken=[]  \n",
    "\t\tchaine=\"  \"\n",
    "\t\tf = open(dir+'\\\\'+file, 'r')\n",
    "\t\ttoken.append(file)\n",
    "\t\tfor line in f.readlines():\n",
    "\t\t\tif len(token)<=4: \n",
    "\t\t\t\ttoken.append(line) \n",
    "\t\t\telse:\n",
    "\t\t\t\tchaine=chaine+line \n",
    "\t\ttoken.append(chaine)                 \n",
    "\t\tf.close()\n",
    "\t\tGtoken.append(token)\n",
    "\treturn Gtoken\n",
    "p=tokenize_text(list_test)\n",
    " \n",
    "def Listing_RBL(x): \n",
    "\topen(\"data.txt\", \"w\").close()    \n",
    "\tbls = [\"zen.spamhaus.org\", \"spam.abuse.ch\", \"cbl.abuseat.org\", \"virbl.dnsbl.bit.nl\", \"dnsbl.inps.de\", \n",
    "\t\"ix.dnsbl.manitu.net\", \"dnsbl.sorbs.net\", \"bl.spamcannibal.org\", \"bl.spamcop.net\", \n",
    "\t\"xbl.spamhaus.org\", \"pbl.spamhaus.org\", \"dnsbl-1.uceprotect.net\", \"dnsbl-2.uceprotect.net\", \n",
    "\t\"dnsbl-3.uceprotect.net\", \"db.wpbl.info\",\"all.s5h.net\",\"b.barracudacentral.org\",\"bl.emailbasura.org\",\n",
    "\"bl.spamcannibal.org\",\"bl.spamcop.net\",\"blacklist.woody.ch\",\n",
    "\"bogons.cymru.com\",\"cbl.abuseat.org\",\"cdl.anti-spam.org.cn\",\n",
    "\"combined.abuse.ch\",\"db.wpbl.info\",\"dnsbl-1.uceprotect.net\",\"wormrbl.imp.ch\",\"xbl.spamhaus.org\",\"z.mailspike.net\",\n",
    "\"zen.spamhaus.org\"]\n",
    "\tdata = socket.gethostbyname(x)\n",
    "\tmyIP =data\n",
    "\tlength=len(bls)\n",
    "\tprint (myIP)\n",
    "\tfor bl in bls:\n",
    "\t\ttry:\n",
    "\t\t\tmy_resolver = dns.resolver.Resolver()\n",
    "\t\t\tquery = '.'.join(reversed(str(myIP).split(\".\"))) + \".\" + bl\n",
    "\t\t\tanswers = my_resolver.query(query, \"A\")\n",
    "\t\t\tanswer_txt = my_resolver.query(query, \"TXT\" )\n",
    "\t\t\tprint ('IP: %s IS listed in %s (%s: %s)' %(myIP, bl, answers[0], answer_txt[0]))\n",
    "\t\texcept dns.resolver.NXDOMAIN:\n",
    "\t\t\tfichier = open(\"data.txt\", \"a+\")\n",
    "\t\t\tfichier.write('NOT_LISTED \\n')\n",
    "\t\texcept socket.gaierror: \n",
    "\t\t\tprint (\"\")\n",
    "\t\texcept dns.resolver.NoNameservers:\n",
    "\t\t\tprint (\"\")\n",
    "\t\texcept dns.resolver.Timeout: \n",
    "\t\t\tprint (\"\")\n",
    "def count_file_line():\n",
    "    f = open(\"data.txt\",\"r\")\n",
    "    l=[]\n",
    "    for line in f.readlines():\n",
    "        l.append(line)\n",
    "    f.close()\n",
    "    return len(l)\n",
    "\n",
    "def metric_FROM(): \n",
    "    #la creation du fichier data.txt est obligatoire à ce niveau avant de commencer \n",
    "    j=count_file_line()# on retourne de degree d'inquiétude 1-degre de safety (NON LISTER ) \n",
    "    return 1-j/31\n",
    "\n",
    "def extract_domain(chaine): \n",
    "    pos=chaine.find('@')\n",
    "    pos2=chaine.find('>')\n",
    "    domaine=chaine[pos+1:pos2]\n",
    "    return domaine \n",
    "\n",
    "def metric_SUBJECT_MESSAGE(subject,message,file):\n",
    "    #traitement subject evalué à 30% \n",
    "    f=open(file,\"r\")\n",
    "    text=f.read() \n",
    "    #text=text.split(',')\n",
    "    sub=0\n",
    "    mes=0\n",
    "    subject=subject.split(' ')\n",
    "    message=message.split(' ')\n",
    "    \n",
    "    for x in subject: \n",
    "        if x in text : \n",
    "            sub=sub+1\n",
    "    for x in message: \n",
    "        if x in text : \n",
    "            mes=mes+1\n",
    "    sub=sub/len(subject) \n",
    "    mes=mes/len(message) \n",
    "    res=sub*0.300 + mes*0.700 \n",
    "    #traitement subject evalué à 70% \n",
    "   \n",
    "    f.close()\n",
    "    return res\n",
    "\n",
    "file=r'C:\\Users\\asus\\Desktop\\Etudes\\S4\\ProjetAI\\jargon.txt'\n",
    "def Quantify(list_train): \n",
    "    p=tokenize_text(list_train)\n",
    "    list=[]\n",
    "    for x in p : \n",
    "        item=[]\n",
    "        domaine=extract_domain(x[2])\n",
    "        Listing_RBL(domaine)\n",
    "        item.append(x[0])\n",
    "        item.append(metric_FROM())\n",
    "        item.append(metric_SUBJECT_MESSAGE(x[4],x[5],file)) \n",
    "        list.append(item)\n",
    "    return list \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.216.111.15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "172.217.19.133\n",
      "\n",
      "\n",
      "\n",
      "82.216.111.15\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p=Quantify(list_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.16129032258064513, 0.31875], [0.19354838709677424, 0.3322222222222222], [0.12903225806451613, 0.4130081300813008], [0.16129032258064513, 0.31749999999999995], [0.19354838709677424, 0.17843137254901958], [0.19354838709677424, 0.15069444444444444], [0.16129032258064513, 0.28385826771653544], [0.12903225806451613, 0.175], [0.12903225806451613, 0.19209302325581395], [0.12903225806451613, 0.12727272727272726]]\n"
     ]
    }
   ],
   "source": [
    "def np_array_format(p):\n",
    "    list=[]\n",
    "    for x in p: \n",
    "        list.append([x[1],x[2]])\n",
    "    return list\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.16129032258064513, 0.175],\n",
       " [0.12903225806451613, 0.182],\n",
       " [0.12903225806451613, 0.23890243902439023]]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p\n",
    "o=np_array_format(p)\n",
    "o"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
